{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport glob\nimport pandas as pd\nfrom tqdm import tqdm\nos.chdir(\"/kaggle/input\")\nimport nltk\nimport matplotlib.pyplot as plt\nfrom nltk import word_tokenize, sent_tokenize\nfrom nltk.corpus import stopwords\nimport numpy as np\nimport ipywidgets as widgets\nfrom ipywidgets import interact, interactive, fixed, interact_manual","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pd.read_csv('/kaggle/input/14-million-cell-phone-reviews/phone_user_review_file_1.csv',encoding=\"ISO-8859-1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame()\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in tqdm(filenames):\n        x = os.path.join(dirname, filename)\n        temp = pd.read_csv(x,encoding=\"ISO-8859-1\")\n#         print(type(x))\n        if df.shape[0] ==0:\n            df = temp\n        else:\n            df = pd.concat([df,temp])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.phone_url.str.split('/')\ndf[df.author == 'ã¦ã©ãã©ãã©ã´ã³']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#using phone url is a better way to identify the product than the product column itself\ny = df['phone_url'].str.split('/',n=-1,expand = True)\ndf['Prod_name'] = y[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df[['date', 'lang', 'country', 'source',  'score','extract', 'author', 'Prod_name']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating null values across dataset\nnd = {}\nfor i in new_df.columns:\n    nd[i] = new_df[i].isnull().sum()\nnd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create year out of date\nx = new_df['date'].str.split('/',n=-1,expand = True)\nnew_df['Year'] = x[2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we saw that the year starts from 1970 with only one phone from sony, which seems very unlikely and hence is an incorrect record and should be removed"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['Year'].hist(xrot=90)\nnp.unique(new_df.Year)\nnew_df[new_df.Year=='1970']\nnew_df = new_df[new_df.Year!='1970']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The purpose of below code block is to find the sentiment scores for all language reviews for which we have stopwords available in NLTK\nThis uses a dataset with abbreviations for languages and the full forms to see if the NLTK has stopwords for those, the dataset has been removed for the purpose of restarting the notebook and keeping the results as it is\nAlso we are calculating which reviewers among these rows with non nulls have amazon in their title- thereby calculating their trends across years and across the source where the reviews are published"},{"metadata":{"trusted":true},"cell_type":"code","source":"lang = pd.read_csv(\"../input/language-codes/language-codes.csv\")\nlang.columns = ['lang','actual']\nnew_df2 = pd.merge(new_df,lang, on='lang')\n#lowercasing the reviews and languages acronyms\nnew_df2['extract'] = new_df2['extract'].astype(str)\nnew_df2['actual'] = new_df2['actual'].astype(str)\nnew_df2['extract'] = new_df2['extract'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\nnew_df2['actual'] = new_df2['actual'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n#removing extract stopwords from all available languages in stopwords list\nlang_av = ['arabic',\n 'chinese',\n 'czech',\n 'danish',\n 'dutch',\n 'english',\n 'finnish',\n 'french',\n 'german',\n 'hebrew',\n 'hungarian',\n 'indonesian',\n 'italian',\n 'japanese',\n 'korean',\n 'norwegian',\n 'polish',\n 'portuguese',\n 'russian',\n 'spanish',\n 'swedish',\n 'turkish']\n# print(stopwords.fileids())\nfinal_df = pd.DataFrame()\nfor i in lang_av:\n    try:\n        stop = stopwords.words(i)\n        temp = new_df2[new_df2.actual == i]\n        temp['extract'] = temp['extract'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n        if final_df.shape[0]==0:\n            final_df = temp\n        else:\n            final_df = pd.concat([final_df,temp])\n    except:\n        pass\n#calculating sentiment score using inbuilt function textblob\nfrom textblob import TextBlob\ndef senti(x):\n    return TextBlob(x).sentiment\nfinal_df_copy=  final_df.copy(deep = True)\nfinal_df_copy['senti_score'] = final_df_copy['extract'].apply(senti)\n#getting rid of null values only to see the anonymous reviews\nfinal_df_copy_nonNull = final_df_copy.dropna(subset = ['author'])\n#the number of reviews given by people with just amazon title\nfinal_df_copy_nonNull[final_df_copy_nonNull['author'].str.match('Amazon')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df_copy.senti_score.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the reviews with amazon heading vary across different countries in following way\nfinal_df_copy_nonNull[final_df_copy_nonNull['author'].str.match('Amazon')].country.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the number of people reviewing with amazon customer as their title has increased significantly in the last 3 years\nfinal_df_copy_nonNull[final_df_copy_nonNull['author'].str.match('Amazon')].Year.hist(xrot = 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This code block creates a visual to see how across all null or non-null reviewers' name, the source has been used across years to write reviews"},{"metadata":{"trusted":true},"cell_type":"code","source":"source_dropdown = widgets.Dropdown(options = list(np.unique(new_df.source)),value= None,description='Select source')\ndef source_variation_across_years(x):\n    selected_source = source_dropdown.value\n    selected_df = new_df[new_df.source == selected_source]\n    selected_df.Year.hist(xrot = 90)\ninteract(source_variation_across_years,x =source_dropdown )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a new column to find the company scores across years\nz = new_df['Prod_name'].str.split('-',n=-1,expand=True)\nnew_df['Company'] = z[0]\nnew_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"companyNnumbers20 = pd.DataFrame(new_df.Company.value_counts()).reset_index().iloc[:20,]\ncompanyNnumbers20.columns = ['CompanyName','Reviews']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"companyNnumbers20","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The below code block shows how the trend of top 20 companies in terms of number of reviews had their trend changed across years across review counts"},{"metadata":{"trusted":true},"cell_type":"code","source":"company_seletion = widgets.Dropdown(options = list(np.unique(companyNnumbers20.CompanyName)),value= None,description='Select company')\ndef company_reviews_across_years(x):\n    selected_company = company_seletion.value\n    selected_df = new_df[new_df.Company == selected_company]\n    selected_df.sort_values(by='Year').Year.hist(xrot = 90)\ninteract(company_reviews_across_years,x =company_seletion )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filled_df = new_df.fillna('ThisOne')\ndict(filled_df[filled_df.score == 'ThisOne'].Company.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we can infer here that 5 countries make up 52000 of 63000 null scores\ncountries_with_nullscores = filled_df[filled_df.score=='ThisOne'].country.value_counts()\ncountries_with_nullscores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#these countries have been chosen because of their null score to total count ratio\ncountries_to_remove = ['tr','fr','br']\nfor i in countries_to_remove:\n    ratio = countries_with_nullscores[i]/len(filled_df[filled_df.country==i])\n    print(f'null to total ratio for {i} is {ratio}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this dataframe is devoid of countries with high null score to total ratio\nnull_score_calc_df = new_df[~new_df.country.isin(countries_to_remove)]\nnull_score_calc_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we can also calculate which coutries have english speaking reviewers\nnew_df.country[new_df.lang == 'en'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.score.fillna(5.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.score.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we calculate the average score for each company across the years and visualize how these scores have varied\nnew_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fdd = pd.DataFrame()\nfor i in tqdm(companyNnumbers20.CompanyName):\n    temp = np.unique(new_df.Year[new_df.Company==i])\n    for j in tqdm(temp):\n        mean_score = np.mean(new_df[(new_df.Company == i) & (new_df.Year == j)].score)\n        temp_df = pd.DataFrame([i,j,mean_score]).T\n        if fdd.shape[0]==0:\n            fdd = temp_df\n        else:\n            fdd = pd.concat([fdd,temp_df])\nfdd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fdd.columns = ['Company','Year','MeanScore']\nfdd.Year = fdd.Year.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"company_seletion = widgets.Dropdown(options = list(np.unique(companyNnumbers20.CompanyName)),value= 'apple',description='Select company')\ndef company_scores_across_years(t):\n    selected_company = company_seletion.value\n    selected_df = fdd[fdd.Company == selected_company]\n    year_list = list(np.unique(selected_df.Year))\n#     return selected_df\n    selected_df.plot.line(x='Year',y='MeanScore',rot=90,marker='o')\n    print(year_list)\n    plt.xticks(year_list)\ninteract(company_scores_across_years,t =company_seletion )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df[(new_df.Year == '2000')&(new_df.Company=='samsung')].Prod_name.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df[(new_df.Year == '2008')&(new_df.Company=='samsung')].Prod_name.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df[(new_df.Year == '1999')&(new_df.Company=='samsung')].Prod_name.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df[(new_df.Year == '2016')&(new_df.Company=='samsung')].Prod_name.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding extra information to identify the products which plummeted the score in that year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}